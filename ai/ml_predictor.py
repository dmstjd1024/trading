"""
ML ê°€ê²© ì˜ˆì¸¡ ëª¨ë“ˆ

ê¸°ìˆ ì  ì§€í‘œì™€ LLM ì„¼í‹°ë©˜íŠ¸ë¥¼ í”¼ì²˜ë¡œ ì‚¬ìš©í•˜ì—¬
XGBoost ëª¨ë¸ë¡œ ê°€ê²© ë°©í–¥ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
"""

from __future__ import annotations

import warnings
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, List, Tuple

import numpy as np
import pandas as pd

from ai.llm_analyzer import MarketAnalysis

warnings.filterwarnings("ignore", category=UserWarning)


# â”€â”€ ì˜ˆì¸¡ ê²°ê³¼ ëª¨ë¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@dataclass
class PricePrediction:
    """ML ê°€ê²© ì˜ˆì¸¡ ê²°ê³¼"""
    direction: str = "flat"        # "up" | "down" | "flat"
    probability: float = 0.5       # ì˜ˆì¸¡ í™•ë¥  0.0 ~ 1.0
    expected_return: float = 0.0   # ì˜ˆìƒ ìˆ˜ìµë¥  (%)
    features_importance: Dict[str, float] = field(default_factory=dict)
    timestamp: datetime = field(default_factory=datetime.now)

    def to_dict(self) -> dict:
        return {
            "direction": self.direction,
            "probability": self.probability,
            "expected_return": self.expected_return,
            "features_importance": self.features_importance,
            "timestamp": self.timestamp.isoformat(),
        }

    @classmethod
    def from_dict(cls, d: dict) -> "PricePrediction":
        return cls(
            direction=d.get("direction", "flat"),
            probability=d.get("probability", 0.5),
            expected_return=d.get("expected_return", 0.0),
            features_importance=d.get("features_importance", {}),
            timestamp=datetime.fromisoformat(d["timestamp"]) if "timestamp" in d else datetime.now(),
        )

    @property
    def direction_score(self) -> float:
        """ë°©í–¥ì„ ìˆ˜ì¹˜ ì ìˆ˜ë¡œ ë³€í™˜ (-1 ~ +1)"""
        mapping = {"up": 1.0, "flat": 0.0, "down": -1.0}
        return mapping.get(self.direction, 0.0) * self.probability

    @property
    def direction_label_kr(self) -> str:
        """í•œêµ­ì–´ ë°©í–¥ ë¼ë²¨"""
        return {"up": "ğŸ“ˆ ìƒìŠ¹ ì˜ˆì¸¡", "flat": "â¡ï¸ ë³´í•© ì˜ˆì¸¡", "down": "ğŸ“‰ í•˜ë½ ì˜ˆì¸¡"}.get(self.direction, "ë³´í•©")


# â”€â”€ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def compute_technical_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    OHLCV ë°ì´í„°ì—ì„œ ê¸°ìˆ ì  ì§€í‘œ í”¼ì²˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

    Args:
        df: open, high, low, close, volume ì»¬ëŸ¼ì„ ê°€ì§„ DataFrame

    Returns:
        í”¼ì²˜ê°€ ì¶”ê°€ëœ DataFrame (ì›ë³¸ ìˆ˜ì • ì•ˆ í•¨)
    """
    data = df.copy()
    close = data["close"]
    volume = data["volume"]

    # â”€â”€ RSI (14ì¼) â”€â”€
    delta = close.diff()
    gain = delta.where(delta > 0, 0.0)
    loss = (-delta).where(delta < 0, 0.0)
    avg_gain = gain.rolling(14, min_periods=14).mean()
    avg_loss = loss.rolling(14, min_periods=14).mean()
    rs = avg_gain / avg_loss.replace(0, np.inf)
    data["feat_rsi"] = 100 - (100 / (1 + rs))

    # â”€â”€ MACD â”€â”€
    ema12 = close.ewm(span=12, adjust=False).mean()
    ema26 = close.ewm(span=26, adjust=False).mean()
    data["feat_macd"] = ema12 - ema26
    data["feat_macd_signal"] = data["feat_macd"].ewm(span=9, adjust=False).mean()
    data["feat_macd_hist"] = data["feat_macd"] - data["feat_macd_signal"]

    # â”€â”€ Bollinger Band ìœ„ì¹˜ (0~1) â”€â”€
    bb_ma = close.rolling(20).mean()
    bb_std = close.rolling(20).std()
    bb_upper = bb_ma + 2 * bb_std
    bb_lower = bb_ma - 2 * bb_std
    bb_range = (bb_upper - bb_lower).replace(0, np.nan)
    data["feat_bb_position"] = (close - bb_lower) / bb_range

    # â”€â”€ ì´ë™í‰ê·  ê¸°ìš¸ê¸° (ì •ê·œí™”) â”€â”€
    for window in [5, 20, 60]:
        ma = close.rolling(window).mean()
        slope = ma.diff(5) / ma.shift(5) * 100  # 5ì¼ê°„ ë³€í™”ìœ¨(%)
        data[f"feat_ma{window}_slope"] = slope

    # â”€â”€ ê°€ê²© ëŒ€ë¹„ ì´ë™í‰ê·  ê´´ë¦¬ìœ¨ â”€â”€
    ma20 = close.rolling(20).mean()
    data["feat_price_ma20_gap"] = (close - ma20) / ma20 * 100

    # â”€â”€ ê±°ë˜ëŸ‰ ë³€í™”ìœ¨ â”€â”€
    vol_ma5 = volume.rolling(5).mean()
    data["feat_volume_ratio"] = volume / vol_ma5.replace(0, np.nan)

    # â”€â”€ ATR (14ì¼) â”€â”€
    high = data["high"]
    low = data["low"]
    prev_close = close.shift(1)
    tr = pd.concat([
        (high - low),
        (high - prev_close).abs(),
        (low - prev_close).abs(),
    ], axis=1).max(axis=1)
    data["feat_atr"] = tr.rolling(14).mean() / close * 100  # ATR ë¹„ìœ¨(%)

    # â”€â”€ ìˆ˜ìµë¥  ê´€ë ¨ â”€â”€
    data["feat_return_1d"] = close.pct_change(1) * 100
    data["feat_return_5d"] = close.pct_change(5) * 100
    data["feat_return_20d"] = close.pct_change(20) * 100

    # â”€â”€ ë³€ë™ì„± â”€â”€
    data["feat_volatility"] = close.pct_change().rolling(20).std() * np.sqrt(252) * 100

    return data


FEATURE_COLUMNS = [
    "feat_rsi",
    "feat_macd",
    "feat_macd_signal",
    "feat_macd_hist",
    "feat_bb_position",
    "feat_ma5_slope",
    "feat_ma20_slope",
    "feat_ma60_slope",
    "feat_price_ma20_gap",
    "feat_volume_ratio",
    "feat_atr",
    "feat_return_1d",
    "feat_return_5d",
    "feat_return_20d",
    "feat_volatility",
]

# LLM ì„¼í‹°ë©˜íŠ¸ í”¼ì²˜ (ë³„ë„ ì¶”ê°€)
SENTIMENT_FEATURES = [
    "feat_sentiment_score",    # outlook ì ìˆ˜ (-1 ~ +1)
    "feat_sentiment_conf",     # confidence (0 ~ 1)
    "feat_risk_score",         # risk level ì ìˆ˜ (0 ~ 1)
]

# ê±°ì‹œ í”¼ì²˜ (ë³„ë„ ì¶”ê°€)
MACRO_FEATURES = [
    "feat_kospi_change",
    "feat_vix_change",
    "feat_usd_krw_change",
    "feat_oil_change",
]


# â”€â”€ ML ì˜ˆì¸¡ê¸° í´ë˜ìŠ¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class MLPredictor:
    """XGBoost ê¸°ë°˜ ê°€ê²© ë°©í–¥ ì˜ˆì¸¡ê¸°"""

    def __init__(
        self,
        model_dir: str = "./data/models",
        prediction_days: int = 5,
    ):
        self.model_dir = Path(model_dir)
        self.model_dir.mkdir(parents=True, exist_ok=True)
        self.prediction_days = prediction_days
        self._models: Dict[str, object] = {}  # stock_code -> model

    def _get_all_feature_cols(self) -> List[str]:
        """ì „ì²´ í”¼ì²˜ ì»¬ëŸ¼ ëª©ë¡"""
        return FEATURE_COLUMNS + SENTIMENT_FEATURES + MACRO_FEATURES

    def _prepare_data(
        self,
        df: pd.DataFrame,
        sentiment_history: Optional[List[MarketAnalysis]] = None,
        macro_data: Optional[dict] = None,
    ) -> Tuple[pd.DataFrame, Optional[pd.Series]]:
        """
        í•™ìŠµ/ì¶”ë¡ ìš© ë°ì´í„° ì¤€ë¹„

        Returns:
            (features_df, target_series) - targetì€ í•™ìŠµ ì‹œì—ë§Œ ì œê³µ
        """
        # ê¸°ìˆ ì  í”¼ì²˜ ê³„ì‚°
        data = compute_technical_features(df)

        # ì„¼í‹°ë©˜íŠ¸ í”¼ì²˜ ì¶”ê°€
        data["feat_sentiment_score"] = 0.0
        data["feat_sentiment_conf"] = 0.5
        data["feat_risk_score"] = 0.5

        if sentiment_history:
            # ê°€ì¥ ìµœê·¼ ì„¼í‹°ë©˜íŠ¸ ì ìš© (ì „ì²´ í–‰ì— ë™ì¼ ê°’)
            latest = sentiment_history[-1]
            data["feat_sentiment_score"] = latest.outlook_score
            data["feat_sentiment_conf"] = latest.confidence
            data["feat_risk_score"] = latest.risk_score

        # ê±°ì‹œ í”¼ì²˜ ì¶”ê°€
        data["feat_kospi_change"] = 0.0
        data["feat_vix_change"] = 0.0
        data["feat_usd_krw_change"] = 0.0
        data["feat_oil_change"] = 0.0

        if macro_data:
            data["feat_kospi_change"] = macro_data.get("kospi_change", 0.0)
            data["feat_vix_change"] = macro_data.get("vix_change", 0.0)
            data["feat_usd_krw_change"] = macro_data.get("usd_krw_change", 0.0)
            data["feat_oil_change"] = macro_data.get("oil_change", 0.0)

        # íƒ€ê²Ÿ: í–¥í›„ Nê±°ë˜ì¼ ìˆ˜ìµë¥ 
        future_return = data["close"].shift(-self.prediction_days) / data["close"] - 1
        # 3ë¶„ë¥˜: up (>1%), down (<-1%), flat
        target = pd.Series("flat", index=data.index)
        target[future_return > 0.01] = "up"
        target[future_return < -0.01] = "down"

        # NaN ì œê±°
        all_features = self._get_all_feature_cols()
        valid_mask = data[all_features].notna().all(axis=1)
        data = data[valid_mask]
        target = target[valid_mask]

        return data, target

    def train(
        self,
        stock_code: str,
        df: pd.DataFrame,
        sentiment_history: Optional[List[MarketAnalysis]] = None,
        macro_data: Optional[dict] = None,
    ) -> Dict:
        """
        ëª¨ë¸ í•™ìŠµ

        Args:
            stock_code: ì¢…ëª© ì½”ë“œ
            df: OHLCV DataFrame
            sentiment_history: LLM ë¶„ì„ ì´ë ¥
            macro_data: ê±°ì‹œê²½ì œ ë³€í™”ìœ¨ dict

        Returns:
            í•™ìŠµ ê²°ê³¼ ë©”íŠ¸ë¦­ dict
        """
        try:
            from xgboost import XGBClassifier
            from sklearn.model_selection import TimeSeriesSplit
            from sklearn.metrics import accuracy_score, classification_report
            from sklearn.preprocessing import LabelEncoder
            import joblib
        except ImportError as e:
            print(f"[AI-ML] í•„ìš” íŒ¨í‚¤ì§€ ë¯¸ì„¤ì¹˜: {e}")
            return {"error": str(e)}

        data, target = self._prepare_data(df, sentiment_history, macro_data)

        if len(data) < 100:
            return {"error": f"í•™ìŠµ ë°ì´í„° ë¶€ì¡± ({len(data)}í–‰, ìµœì†Œ 100í–‰ í•„ìš”)"}

        # íƒ€ê²Ÿì—ì„œ ë¯¸ë˜ ë°ì´í„°ê°€ ì—†ëŠ” í–‰ ì œê±°
        valid_idx = target.index[target.notna()]
        # ë§ˆì§€ë§‰ prediction_days ê°œëŠ” íƒ€ê²Ÿì„ ì•Œ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ì œì™¸
        train_end = len(data) - self.prediction_days
        if train_end < 50:
            return {"error": "í•™ìŠµ ê°€ëŠ¥ ë°ì´í„° ë¶€ì¡±"}

        all_features = self._get_all_feature_cols()
        X = data[all_features].iloc[:train_end].values
        y_raw = target.iloc[:train_end]

        # ë¼ë²¨ ì¸ì½”ë”©
        le = LabelEncoder()
        y = le.fit_transform(y_raw)

        # ì‹œê³„ì—´ êµì°¨ê²€ì¦
        tscv = TimeSeriesSplit(n_splits=3)
        scores = []

        model = XGBClassifier(
            n_estimators=200,
            max_depth=6,
            learning_rate=0.05,
            subsample=0.8,
            colsample_bytree=0.8,
            use_label_encoder=False,
            eval_metric="mlogloss",
            random_state=42,
            verbosity=0,
        )

        for train_idx, val_idx in tscv.split(X):
            X_train, X_val = X[train_idx], X[val_idx]
            y_train, y_val = y[train_idx], y[val_idx]

            model.fit(X_train, y_train)
            y_pred = model.predict(X_val)
            scores.append(accuracy_score(y_val, y_pred))

        # ì „ì²´ ë°ì´í„°ë¡œ ìµœì¢… í•™ìŠµ
        model.fit(X, y)

        # ëª¨ë¸ ì €ì¥
        model_path = self.model_dir / f"{stock_code}_xgb.pkl"
        joblib.dump({"model": model, "label_encoder": le, "features": all_features}, model_path)
        self._models[stock_code] = {"model": model, "label_encoder": le, "features": all_features}

        # í”¼ì²˜ ì¤‘ìš”ë„
        importance = dict(zip(all_features, model.feature_importances_.tolist()))
        sorted_importance = dict(sorted(importance.items(), key=lambda x: x[1], reverse=True)[:10])

        return {
            "stock_code": stock_code,
            "cv_accuracy": np.mean(scores),
            "cv_scores": scores,
            "train_samples": len(X),
            "features_importance": sorted_importance,
            "model_path": str(model_path),
        }

    def predict(
        self,
        stock_code: str,
        df: pd.DataFrame,
        current_sentiment: Optional[MarketAnalysis] = None,
        macro_data: Optional[dict] = None,
    ) -> PricePrediction:
        """
        ê°€ê²© ë°©í–¥ ì˜ˆì¸¡

        Args:
            stock_code: ì¢…ëª© ì½”ë“œ
            df: ìµœì‹  OHLCV DataFrame
            current_sentiment: í˜„ì¬ LLM ì‹œì¥ ë¶„ì„
            macro_data: í˜„ì¬ ê±°ì‹œê²½ì œ ë³€í™”ìœ¨

        Returns:
            PricePrediction ì˜ˆì¸¡ ê²°ê³¼
        """
        try:
            import joblib
        except ImportError:
            return self._demo_prediction()

        # ëª¨ë¸ ë¡œë“œ
        if stock_code not in self._models:
            model_path = self.model_dir / f"{stock_code}_xgb.pkl"
            if model_path.exists():
                self._models[stock_code] = joblib.load(model_path)
            else:
                print(f"[AI-ML] {stock_code} ëª¨ë¸ ì—†ìŒ â€” ë°ëª¨ ì˜ˆì¸¡ ë°˜í™˜")
                return self._demo_prediction()

        model_data = self._models[stock_code]
        model = model_data["model"]
        le = model_data["label_encoder"]
        feature_cols = model_data["features"]

        # í”¼ì²˜ ì¤€ë¹„
        sentiment_history = [current_sentiment] if current_sentiment else None
        data, _ = self._prepare_data(df, sentiment_history, macro_data)

        if data.empty:
            return self._demo_prediction()

        # ìµœì‹  í–‰ìœ¼ë¡œ ì˜ˆì¸¡
        X_latest = data[feature_cols].iloc[[-1]].values
        pred_class = model.predict(X_latest)[0]
        pred_proba = model.predict_proba(X_latest)[0]

        direction = le.inverse_transform([pred_class])[0]
        probability = float(pred_proba.max())

        # ì˜ˆìƒ ìˆ˜ìµë¥  ì¶”ì • (ë‹¨ìˆœ ì„ í˜• ë§µí•‘)
        if direction == "up":
            expected_return = probability * 3.0  # ìµœëŒ€ 3%
        elif direction == "down":
            expected_return = -probability * 3.0
        else:
            expected_return = 0.0

        # í”¼ì²˜ ì¤‘ìš”ë„
        importance = dict(zip(feature_cols, model.feature_importances_.tolist()))
        top_features = dict(sorted(importance.items(), key=lambda x: x[1], reverse=True)[:8])

        return PricePrediction(
            direction=direction,
            probability=probability,
            expected_return=expected_return,
            features_importance=top_features,
            timestamp=datetime.now(),
        )

    def _demo_prediction(self) -> PricePrediction:
        """ë°ëª¨ìš© ì˜ˆì¸¡ ê²°ê³¼"""
        return PricePrediction(
            direction="up",
            probability=0.68,
            expected_return=2.04,
            features_importance={
                "feat_rsi": 0.15,
                "feat_macd_hist": 0.13,
                "feat_sentiment_score": 0.12,
                "feat_ma20_slope": 0.10,
                "feat_volume_ratio": 0.09,
                "feat_bb_position": 0.08,
                "feat_return_5d": 0.07,
                "feat_kospi_change": 0.06,
            },
            timestamp=datetime.now(),
        )

    def is_trained(self, stock_code: str) -> bool:
        """í•´ë‹¹ ì¢…ëª©ì˜ í•™ìŠµëœ ëª¨ë¸ì´ ìˆëŠ”ì§€ í™•ì¸"""
        if stock_code in self._models:
            return True
        model_path = self.model_dir / f"{stock_code}_xgb.pkl"
        return model_path.exists()
