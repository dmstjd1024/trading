"""
LLM ì‹œì¥ ë¶„ì„ ëª¨ë“ˆ

ê²½ì œ ë‰´ìŠ¤, ê±°ì‹œê²½ì œ ì§€í‘œ, ì‹œì¥ ì‹¬ë¦¬ ë°ì´í„°ë¥¼ ì¢…í•©í•˜ì—¬
LLM(Gemini/GPT/Claude)ì„ í†µí•´ ì‹œì¥ ì „ë§ì„ ë¶„ì„í•©ë‹ˆë‹¤.
"""

from __future__ import annotations

import json
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict

from ai.data_sources import EconomicDataAggregator, _FileCache


# â”€â”€ ë¶„ì„ ê²°ê³¼ ëª¨ë¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@dataclass
class MarketAnalysis:
    """LLM ì‹œì¥ ë¶„ì„ ê²°ê³¼"""
    outlook: str = "neutral"         # "bullish" | "bearish" | "neutral"
    confidence: float = 0.5          # 0.0 ~ 1.0
    reasoning: str = ""              # ë¶„ì„ ê·¼ê±° (í•œê¸€)
    sector_outlook: Dict[str, str] = field(default_factory=dict)  # {"ë°˜ë„ì²´": "bullish", ...}
    risk_level: str = "medium"       # "low" | "medium" | "high"
    key_factors: list = field(default_factory=list)  # ì£¼ìš” ì˜í–¥ ìš”ì¸
    timestamp: datetime = field(default_factory=datetime.now)

    def to_dict(self) -> dict:
        return {
            "outlook": self.outlook,
            "confidence": self.confidence,
            "reasoning": self.reasoning,
            "sector_outlook": self.sector_outlook,
            "risk_level": self.risk_level,
            "key_factors": self.key_factors,
            "timestamp": self.timestamp.isoformat(),
        }

    @classmethod
    def from_dict(cls, d: dict) -> "MarketAnalysis":
        return cls(
            outlook=d.get("outlook", "neutral"),
            confidence=d.get("confidence", 0.5),
            reasoning=d.get("reasoning", ""),
            sector_outlook=d.get("sector_outlook", {}),
            risk_level=d.get("risk_level", "medium"),
            key_factors=d.get("key_factors", []),
            timestamp=datetime.fromisoformat(d["timestamp"]) if "timestamp" in d else datetime.now(),
        )

    @property
    def outlook_score(self) -> float:
        """ì „ë§ì„ ìˆ˜ì¹˜ ì ìˆ˜ë¡œ ë³€í™˜ (-1 ~ +1)"""
        mapping = {"bullish": 1.0, "neutral": 0.0, "bearish": -1.0}
        return mapping.get(self.outlook, 0.0) * self.confidence

    @property
    def risk_score(self) -> float:
        """ë¦¬ìŠ¤í¬ ë ˆë²¨ì„ ìˆ˜ì¹˜ë¡œ ë³€í™˜ (0~1, ë†’ì„ìˆ˜ë¡ ìœ„í—˜)"""
        return {"low": 0.2, "medium": 0.5, "high": 0.8}.get(self.risk_level, 0.5)

    @property
    def outlook_label_kr(self) -> str:
        """í•œêµ­ì–´ ì „ë§ ë¼ë²¨"""
        return {"bullish": "ğŸŸ¢ ê°•ì„¸", "neutral": "ğŸŸ¡ ë³´í•©", "bearish": "ğŸ”´ ì•½ì„¸"}.get(self.outlook, "ë³´í•©")


# â”€â”€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SYSTEM_PROMPT = """ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ì‹œì¥ ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ê²½ì œ ë°ì´í„°(ë‰´ìŠ¤, ê±°ì‹œì§€í‘œ, ì‹¬ë¦¬ì§€í‘œ)ë¥¼ ì¢…í•© ë¶„ì„í•˜ì—¬ ì‹œì¥ ì „ë§ì„ ì œê³µí•©ë‹ˆë‹¤.

ë¶„ì„ ì‹œ ë‹¤ìŒ ì‚¬í•­ì„ ê³ ë ¤í•˜ì„¸ìš”:
1. ê¸€ë¡œë²Œ ê²½ì œ íë¦„ì´ í•œêµ­ ì‹œì¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥
2. í™˜ìœ¨Â·ê¸ˆë¦¬Â·ìœ ê°€ ë³€ë™ê³¼ í•œêµ­ ìˆ˜ì¶œê¸°ì—…ì— ëŒ€í•œ ì˜í–¥
3. íˆ¬ìì ì‹¬ë¦¬(ê³µí¬/íƒìš•ì§€ìˆ˜, ì™¸êµ­ì¸Â·ê¸°ê´€ ë§¤ë§¤ ë™í–¥)
4. ë‰´ìŠ¤ í—¤ë“œë¼ì¸ì˜ ì „ì²´ì ì¸ í†¤ê³¼ ë°©í–¥ì„±

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš” (ì„¤ëª… í…ìŠ¤íŠ¸ ì—†ì´ JSONë§Œ):
{
    "outlook": "bullish" ë˜ëŠ” "bearish" ë˜ëŠ” "neutral",
    "confidence": 0.0~1.0 ì‚¬ì´ ìˆ«ì,
    "reasoning": "í•œêµ­ì–´ë¡œ 2~3ë¬¸ì¥ì˜ ë¶„ì„ ê·¼ê±°",
    "sector_outlook": {"ì„¹í„°ëª…": "bullish/bearish/neutral", ...},
    "risk_level": "low" ë˜ëŠ” "medium" ë˜ëŠ” "high",
    "key_factors": ["í•µì‹¬ ìš”ì¸ 1", "í•µì‹¬ ìš”ì¸ 2", ...]
}"""


# â”€â”€ LLM ë¶„ì„ê¸° í´ë˜ìŠ¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class LLMAnalyzer:
    """LLM ê¸°ë°˜ ì‹œì¥ ë¶„ì„ê¸°"""

    def __init__(
        self,
        provider: str = "gemini",
        api_key: str = "",
        model: str = "gemini-2.5-flash",
        cache_dir: str = "./data/ai_cache",
    ):
        self.provider = provider
        self.api_key = api_key
        self.model = model
        self._cache = _FileCache(cache_dir)
        self._data_aggregator = EconomicDataAggregator(cache_dir)

    def analyze(self, force_refresh: bool = False) -> MarketAnalysis:
        """
        ì‹œì¥ ì „ë§ ë¶„ì„ ì‹¤í–‰

        Args:
            force_refresh: Trueë©´ ìºì‹œ ë¬´ì‹œí•˜ê³  ìƒˆë¡œ ë¶„ì„

        Returns:
            MarketAnalysis ë¶„ì„ ê²°ê³¼
        """
        # ìºì‹œ í™•ì¸ (í•˜ë£¨ 2íšŒ = 12ì‹œê°„ TTL)
        if not force_refresh:
            cached = self._cache.get("llm_analysis", ttl_seconds=43200)
            if cached:
                return MarketAnalysis.from_dict(cached)

        # ê²½ì œ ë°ì´í„° ìˆ˜ì§‘
        econ_data = self._data_aggregator.collect_all()
        prompt_text = self._data_aggregator.to_llm_prompt(econ_data)

        # LLM í˜¸ì¶œ
        if not self.api_key:
            print("[AI-LLM] API í‚¤ ë¯¸ì„¤ì • â€” ë°ëª¨ ë¶„ì„ ê²°ê³¼ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return self._demo_analysis()

        try:
            if self.provider == "gemini":
                result = self._call_gemini(prompt_text)
            elif self.provider == "openai":
                result = self._call_openai(prompt_text)
            elif self.provider == "anthropic":
                result = self._call_anthropic(prompt_text)
            else:
                print(f"[AI-LLM] ë¯¸ì§€ì› í”„ë¡œë°”ì´ë”: {self.provider}")
                return self._demo_analysis()
        except Exception as e:
            print(f"[AI-LLM] API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return self._demo_analysis()

        # ê²°ê³¼ íŒŒì‹±
        analysis = self._parse_response(result)

        # ìºì‹±
        self._cache.set("llm_analysis", analysis.to_dict())

        return analysis

    def _call_gemini(self, user_prompt: str) -> str:
        """Google Gemini API í˜¸ì¶œ (ë¬´ë£Œ í‹°ì–´ ì§€ì›)"""
        try:
            from google import genai
            from google.genai import types
        except ImportError:
            raise ImportError("google-genai íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. pip install google-genai")

        client = genai.Client(api_key=self.api_key)
        model_name = self.model if "gemini" in self.model else "gemini-2.5-flash"

        # 2.5 ëª¨ë¸ì€ thinking ë¹„í™œì„±í™” (í† í° ì ˆì•½, JSON ì‘ë‹µ ì•ˆì •ì„±)
        thinking_config = None
        if "2.5" in model_name:
            thinking_config = types.ThinkingConfig(thinking_budget=0)

        response = client.models.generate_content(
            model=model_name,
            contents=f"ì˜¤ëŠ˜ì˜ ê²½ì œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ í•œêµ­ ì£¼ì‹ì‹œì¥ ì „ë§ì„ ì œê³µí•´ì£¼ì„¸ìš”.\n\n{user_prompt}",
            config=types.GenerateContentConfig(
                system_instruction=SYSTEM_PROMPT,
                temperature=0.3 if "2.5" not in model_name else 1.0,
                max_output_tokens=2048,
                response_mime_type="application/json",
                thinking_config=thinking_config,
            ),
        )
        return response.text

    def _call_openai(self, user_prompt: str) -> str:
        """OpenAI API í˜¸ì¶œ"""
        try:
            from openai import OpenAI
        except ImportError:
            raise ImportError("openai íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. pip install openai")

        client = OpenAI(api_key=self.api_key)
        response = client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": f"ì˜¤ëŠ˜ì˜ ê²½ì œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ í•œêµ­ ì£¼ì‹ì‹œì¥ ì „ë§ì„ ì œê³µí•´ì£¼ì„¸ìš”.\n\n{user_prompt}"},
            ],
            temperature=0.3,
            max_tokens=1000,
            response_format={"type": "json_object"},
        )
        return response.choices[0].message.content

    def _call_anthropic(self, user_prompt: str) -> str:
        """Anthropic API í˜¸ì¶œ"""
        try:
            import anthropic
        except ImportError:
            raise ImportError("anthropic íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. pip install anthropic")

        client = anthropic.Anthropic(api_key=self.api_key)
        response = client.messages.create(
            model=self.model if "claude" in self.model else "claude-sonnet-4-20250514",
            max_tokens=1000,
            system=SYSTEM_PROMPT,
            messages=[
                {"role": "user", "content": f"ì˜¤ëŠ˜ì˜ ê²½ì œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ í•œêµ­ ì£¼ì‹ì‹œì¥ ì „ë§ì„ ì œê³µí•´ì£¼ì„¸ìš”.\n\n{user_prompt}"},
            ],
        )
        return response.content[0].text

    def _parse_response(self, response_text: str) -> MarketAnalysis:
        """LLM ì‘ë‹µì„ MarketAnalysisë¡œ íŒŒì‹±"""
        try:
            # JSON ë¸”ë¡ ì¶”ì¶œ (```json ... ``` í˜•íƒœì¼ ìˆ˜ ìˆìŒ)
            text = response_text.strip()
            if "```json" in text:
                text = text.split("```json")[1].split("```")[0].strip()
            elif "```" in text:
                text = text.split("```")[1].split("```")[0].strip()

            data = json.loads(text)

            return MarketAnalysis(
                outlook=data.get("outlook", "neutral"),
                confidence=min(1.0, max(0.0, float(data.get("confidence", 0.5)))),
                reasoning=data.get("reasoning", ""),
                sector_outlook=data.get("sector_outlook", {}),
                risk_level=data.get("risk_level", "medium"),
                key_factors=data.get("key_factors", []),
                timestamp=datetime.now(),
            )
        except (json.JSONDecodeError, ValueError, KeyError) as e:
            print(f"[AI-LLM] ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return self._demo_analysis()

    def _demo_analysis(self) -> MarketAnalysis:
        """ë°ëª¨ìš© ë¶„ì„ ê²°ê³¼"""
        return MarketAnalysis(
            outlook="bullish",
            confidence=0.72,
            reasoning=(
                "ë°˜ë„ì²´ ìˆ˜ì¶œ í˜¸ì¡°ì™€ ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ ì „í™˜ì´ ê¸ì •ì ì…ë‹ˆë‹¤. "
                "ë‹¤ë§Œ í™˜ìœ¨ ë³€ë™ì„±ê³¼ ë¯¸êµ­ ê¸ˆë¦¬ ë¶ˆí™•ì‹¤ì„±ì´ ìƒìŠ¹ í­ì„ ì œí•œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
                "ì „ë°˜ì ìœ¼ë¡œ ì½”ìŠ¤í”¼ 2,600ì„  ì´ìƒ ì•ˆì°©ì„ ì‹œë„í•  ê²ƒìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤."
            ),
            sector_outlook={
                "ë°˜ë„ì²´": "bullish",
                "ìë™ì°¨": "bullish",
                "ê¸ˆìœµ": "neutral",
                "ë°”ì´ì˜¤": "neutral",
                "ê±´ì„¤": "bearish",
            },
            risk_level="medium",
            key_factors=[
                "ë°˜ë„ì²´ ìˆ˜ì¶œ ì¦ê°€ì„¸ ì§€ì†",
                "ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ ì „í™˜",
                "ë¯¸ ì—°ì¤€ ê¸ˆë¦¬ì¸í•˜ ê¸°ëŒ€",
                "ì›/ë‹¬ëŸ¬ í™˜ìœ¨ ì•ˆì •í™”",
            ],
            timestamp=datetime.now(),
        )

    def get_latest_analysis(self) -> Optional[MarketAnalysis]:
        """ê°€ì¥ ìµœê·¼ ìºì‹œëœ ë¶„ì„ ê²°ê³¼ ë°˜í™˜ (ì—†ìœ¼ë©´ None)"""
        cached = self._cache.get("llm_analysis", ttl_seconds=86400)  # 24ì‹œê°„ ë‚´ ê²°ê³¼
        if cached:
            return MarketAnalysis.from_dict(cached)
        return None
